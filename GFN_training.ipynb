{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751fb547ec8e93ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T14:52:05.841462Z",
     "start_time": "2025-11-29T14:51:59.110038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import the stuff we need\n",
    "import torch\n",
    "from gflownet.config import init_empty, Config\n",
    "from gflownet.models.graph_transformer import GraphTransformerGFN\n",
    "from gflownet.envs.graph_building_env import GraphBuildingEnv\n",
    "from gflownet.envs.frag_mol_env import FragMolBuildingEnvContext\n",
    "from gflownet.algo.trajectory_balance import TrajectoryBalance\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Get the logger\n",
    "lg = RDLogger.logger()\n",
    "\n",
    "# Disable all RDKit warnings\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "def graph_to_obj(self, g):\n",
    "\n",
    "    def safe_mol(m):\n",
    "        \"\"\"Convert None or invalid input into an empty RDKit molecule.\"\"\"\n",
    "        return m if isinstance(m, Chem.Mol) else Chem.RWMol().GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Base molecule: always start with an empty mol\n",
    "    # ---------------------------------------------------------\n",
    "    mol = Chem.RWMol().GetMol()      # <-- ALWAYS valid, never None\n",
    "    first = True                     # track first fragment\n",
    "\n",
    "    # Atom index offsets\n",
    "    offsets = np.cumsum(\n",
    "        [0] + [self.frags_numatm[g.nodes[i][\"v\"]] for i in g]\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) Add all fragments\n",
    "    # ---------------------------------------------------------\n",
    "    for i in g.nodes:\n",
    "        idx = g.nodes[i][\"v\"]\n",
    "\n",
    "        # force fragment into a valid molecule\n",
    "        frag = safe_mol(self.frags_mol[idx])\n",
    "\n",
    "        if first:\n",
    "            mol = frag\n",
    "            first = False\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol, frag)\n",
    "\n",
    "    # If graph had *no nodes*, mol is still empty â€” that's OK!\n",
    "    rw = Chem.RWMol(mol)  # <-- NOW GUARANTEED SAFE\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) Add bonds\n",
    "    # ---------------------------------------------------------\n",
    "    bond_atoms = []\n",
    "    for a, b in g.edges:\n",
    "        afrag = g.nodes[a][\"v\"]\n",
    "        bfrag = g.nodes[b][\"v\"]\n",
    "\n",
    "        src = g.edges[(a, b)].get(\"src_attach\", 0)\n",
    "        dst = g.edges[(a, b)].get(\"dst_attach\", 0)\n",
    "\n",
    "        try:\n",
    "            u = int(self.frags_stems[afrag][src] + offsets[a])\n",
    "            v = int(self.frags_stems[bfrag][dst] + offsets[b])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rw.AddBond(u, v, Chem.BondType.SINGLE)\n",
    "            bond_atoms.extend([u, v])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    mol = rw.GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4) Remove one H from each attachment atom if possible\n",
    "    # ---------------------------------------------------------\n",
    "    for idx in bond_atoms:\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        h = atom.GetNumExplicitHs()\n",
    "        if h > 0:\n",
    "            atom.SetNumExplicitHs(h - 1)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5) Try sanitizing, but tolerate failure\n",
    "    # ---------------------------------------------------------\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FragMolBuildingEnvContext.graph_to_obj = graph_to_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958c815e8650f898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:44.593469Z",
     "start_time": "2025-11-25T20:17:44.354022Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # For demonstration purposes\n",
    "cfg = Config()\n",
    "env = GraphBuildingEnv()\n",
    "ctx = FragMolBuildingEnvContext()\n",
    "model = GraphTransformerGFN(ctx, cfg)\n",
    "algo = TrajectoryBalance(env, ctx, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce09c59c864edbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:46.688966Z",
     "start_time": "2025-11-25T20:17:46.679011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device('cpu')\n",
    "dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba5674ac77afc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:54.576213Z",
     "start_time": "2025-11-25T20:17:51.353614Z"
    }
   },
   "outputs": [],
   "source": [
    "from gflownet.tasks.seh_frag import SEHTask\n",
    "task = SEHTask(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42fc64c0d8ea240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:18:42.844207Z",
     "start_time": "2025-11-25T20:18:42.840546Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from logger import *\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "import base64\n",
    "from gflownet.envs.graph_building_env import ActionIndex, Graph\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "\n",
    "def imagefn(mols):\n",
    "    out = []\n",
    "    for mol in mols:\n",
    "        if mol is None:\n",
    "            out.append(None)\n",
    "            continue\n",
    "        svg_obj = Draw.MolsToGridImage([mol], molsPerRow=1, subImgSize=(200, 200), useSVG=True)\n",
    "        svg_str = svg_obj.data if hasattr(svg_obj, \"data\") else svg_obj._repr_svg_()\n",
    "        b64 = base64.b64encode(svg_str.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        out.append(b64)\n",
    "    return out\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def featurefn(mol_list, radius=2, n_bits=1024):\n",
    "    \"\"\"\n",
    "    Compute Morgan fingerprints for a list of RDKit molecules, handling partial/incomplete molecules.\n",
    "    \n",
    "    Returns:\n",
    "        fps: np.ndarray of shape (len(mol_list), n_bits)\n",
    "        success_mask: list of bool, True if fingerprint computed successfully, False if fallback used\n",
    "    \"\"\"\n",
    "    fps = np.zeros((len(mol_list), n_bits), dtype=np.uint8)\n",
    "    success_mask = [False] * len(mol_list)\n",
    "\n",
    "    for i, mol in enumerate(mol_list):\n",
    "        if mol is None or mol.GetNumAtoms() == 0:\n",
    "            continue  # leave as zero and False\n",
    "        try:\n",
    "            mol_copy = Chem.Mol(mol)\n",
    "            # Try to sanitize, skip kekulization to avoid RingInfo errors\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol_copy, Chem.SANITIZE_ALL ^ Chem.SANITIZE_KEKULIZE)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Compute Morgan fingerprint\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol_copy, radius=radius, nBits=n_bits)\n",
    "            arr = np.zeros((n_bits,), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "            fps[i] = arr.astype(np.uint8)\n",
    "\n",
    "            success_mask[i] = True\n",
    "        except Exception as e:\n",
    "            # Leave as zero vector, success_mask[i] remains False\n",
    "            #print(f\"{i}: fingerprint failed -> {e}\")\n",
    "            pass\n",
    "\n",
    "    return fps, success_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def textfn(mol_list):\n",
    "    smiles_list = []\n",
    "    for mol in mol_list:\n",
    "        if mol is None:\n",
    "            smiles_list.append(\"[INVALID_NONE]\")\n",
    "            continue\n",
    "        try:\n",
    "            # Try normal smiles\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False)\n",
    "            if smi:\n",
    "                smiles_list.append(smi)\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # Try unsanitized SMILES fallback\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False, isomericSmiles=False)\n",
    "            smiles_list.append(smi if smi else \"[INVALID_EMPTY]\")\n",
    "        except:\n",
    "            smiles_list.append(\"[INVALID_ERROR]\")\n",
    "    return smiles_list\n",
    "        \n",
    "\n",
    "logger = VisLogger(\n",
    "    #path=\"./seh1\",\n",
    "    s0_included = True,\n",
    "    fn_compute_features=featurefn,\n",
    "    fn_state_to_text=textfn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf58ad1-a78e-4e40-a843-ebe38a721214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, n)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs))}, obj_props)\n",
    "        batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "        _, _, losses = algo.compute_batch_losses(model, batch)\n",
    "        #losses.append(loss.item())\n",
    "        avg_rewards.append((log_rewards).exp().mean().item())\n",
    "    batch_idx = []\n",
    "    states = []\n",
    "    logprobs_bw=[]\n",
    "    logprobs_fw=[]\n",
    "    for j, t in enumerate(trajs):\n",
    "        tl = len(t[\"traj\"])\n",
    "        batch_idx += [j]*tl\n",
    "        for s in t[\"traj\"]:\n",
    "            states.append(s[0])\n",
    "        logprobs_bw.append(t[\"bck_logprobs\"])\n",
    "        # shift to next one\n",
    "        logprobs_fw.append(torch.cat((torch.Tensor([0]), t[\"fwd_logprobs\"][:-1])))\n",
    "    return np.array(batch_idx), states, log_rewards.exp(), losses, torch.cat(logprobs_fw), torch.cat(logprobs_bw)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5deddd774150a3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:19:56.858156Z",
     "start_time": "2025-11-25T20:19:56.799160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9e39f99f1b4d24809ae5bfc1be9608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2159,)\n",
      "2159\n",
      "torch.Size([100])\n",
      "100\n",
      "torch.Size([2159])\n",
      "torch.Size([2159])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'GetNumAtoms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(logprobs_bw\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m     38\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39mbatch_idx,\n\u001b[1;32m     39\u001b[0m     states\u001b[38;5;241m=\u001b[39mstates,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logprobs_forward \u001b[38;5;241m=\u001b[39m logprobs_fw\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_to_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/Master/pilot/logger.py:297\u001b[0m, in \u001b[0;36mVisLogger.write_to_db\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn_compute_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     features, features_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn_compute_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_valid_computed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features_valid\n\u001b[1;32m    299\u001b[0m     feature_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputed_features_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m, in \u001b[0;36mfeaturefn\u001b[0;34m(mol_list, radius, n_bits)\u001b[0m\n\u001b[1;32m     34\u001b[0m success_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(mol_list)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mol \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mol_list):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mmol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetNumAtoms\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# leave as zero and False\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'GetNumAtoms'"
     ]
    }
   ],
   "source": [
    "beta = 32\n",
    "log_every = 3\n",
    "iterations = 9\n",
    "samples_per_log = 100\n",
    "losses = []\n",
    "avg_rewards = []\n",
    "opt = torch.optim.Adam(model.parameters(), 3e-4)\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, 64)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs)) * beta}, obj_props)\n",
    "\n",
    "    batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "    loss, _, _ = algo.compute_batch_losses(model, batch)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    avg_rewards.append((log_rewards / beta).exp().mean().item())\n",
    "\n",
    "    #logging\n",
    "    if (i+1)%log_every==0:\n",
    "        # sample new ones on policy\n",
    "        batch_idx, states, rewards, loss, logprobs_fw, logprobs_bw = sample(samples_per_log)\n",
    "        print(batch_idx.shape)\n",
    "        print(len(states))\n",
    "        print(rewards.shape)\n",
    "        print(len(loss))\n",
    "        print(logprobs_fw.shape)\n",
    "        print(logprobs_bw.shape)\n",
    "    \n",
    "        logger.log(\n",
    "            batch_idx=batch_idx,\n",
    "            states=states,\n",
    "            total_reward=rewards,\n",
    "            loss = loss,\n",
    "            iteration=i,\n",
    "            logprobs_backward = logprobs_bw,\n",
    "            logprobs_forward = logprobs_fw\n",
    "        )\n",
    "        logger.write_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361df27-2d07-4293-844d-d1ca710bbb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
