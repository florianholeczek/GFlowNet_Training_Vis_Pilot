{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751fb547ec8e93ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:08:38.520240Z",
     "start_time": "2026-01-12T23:08:34.543758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import the stuff we need\n",
    "import torch\n",
    "from gflownet.config import init_empty, Config\n",
    "from gflownet.models.graph_transformer import GraphTransformerGFN\n",
    "from gflownet.envs.graph_building_env import GraphBuildingEnv\n",
    "from gflownet.envs.frag_mol_env import FragMolBuildingEnvContext\n",
    "from gflownet.algo.trajectory_balance import TrajectoryBalance\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Get the logger\n",
    "lg = RDLogger.logger()\n",
    "\n",
    "# Disable all RDKit warnings\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "def graph_to_obj(self, g):\n",
    "\n",
    "    def safe_mol(m):\n",
    "        \"\"\"Convert None or invalid input into an empty RDKit molecule.\"\"\"\n",
    "        return m if isinstance(m, Chem.Mol) else Chem.RWMol().GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Base molecule: always start with an empty mol\n",
    "    # ---------------------------------------------------------\n",
    "    mol = Chem.RWMol().GetMol()      # <-- ALWAYS valid, never None\n",
    "    first = True                     # track first fragment\n",
    "\n",
    "    # Atom index offsets\n",
    "    offsets = np.cumsum(\n",
    "        [0] + [self.frags_numatm[g.nodes[i][\"v\"]] for i in g]\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) Add all fragments\n",
    "    # ---------------------------------------------------------\n",
    "    for i in g.nodes:\n",
    "        idx = g.nodes[i][\"v\"]\n",
    "\n",
    "        # force fragment into a valid molecule\n",
    "        frag = safe_mol(self.frags_mol[idx])\n",
    "\n",
    "        if first:\n",
    "            mol = frag\n",
    "            first = False\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol, frag)\n",
    "\n",
    "    # If graph had *no nodes*, mol is still empty â€” that's OK!\n",
    "    rw = Chem.RWMol(mol)  # <-- NOW GUARANTEED SAFE\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) Add bonds\n",
    "    # ---------------------------------------------------------\n",
    "    bond_atoms = []\n",
    "    for a, b in g.edges:\n",
    "        afrag = g.nodes[a][\"v\"]\n",
    "        bfrag = g.nodes[b][\"v\"]\n",
    "\n",
    "        src = g.edges[(a, b)].get(\"src_attach\", 0)\n",
    "        dst = g.edges[(a, b)].get(\"dst_attach\", 0)\n",
    "\n",
    "        try:\n",
    "            u = int(self.frags_stems[afrag][src] + offsets[a])\n",
    "            v = int(self.frags_stems[bfrag][dst] + offsets[b])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rw.AddBond(u, v, Chem.BondType.SINGLE)\n",
    "            bond_atoms.extend([u, v])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    mol = rw.GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4) Remove one H from each attachment atom if possible\n",
    "    # ---------------------------------------------------------\n",
    "    for idx in bond_atoms:\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        h = atom.GetNumExplicitHs()\n",
    "        if h > 0:\n",
    "            atom.SetNumExplicitHs(h - 1)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5) Try sanitizing, but tolerate failure\n",
    "    # ---------------------------------------------------------\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FragMolBuildingEnvContext.graph_to_obj = graph_to_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958c815e8650f898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:44.593469Z",
     "start_time": "2025-11-25T20:17:44.354022Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # For demonstration purposes\n",
    "cfg = Config()\n",
    "env = GraphBuildingEnv()\n",
    "ctx = FragMolBuildingEnvContext()\n",
    "model = GraphTransformerGFN(ctx, cfg)\n",
    "algo = TrajectoryBalance(env, ctx, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce09c59c864edbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:46.688966Z",
     "start_time": "2025-11-25T20:17:46.679011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device('cpu')\n",
    "dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba5674ac77afc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:54.576213Z",
     "start_time": "2025-11-25T20:17:51.353614Z"
    }
   },
   "outputs": [],
   "source": [
    "from gflownet.tasks.seh_frag import SEHTask\n",
    "task = SEHTask(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42fc64c0d8ea240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:18:42.844207Z",
     "start_time": "2025-11-25T20:18:42.840546Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from logger import *\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "import base64\n",
    "from gflownet.envs.graph_building_env import ActionIndex, Graph\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "\n",
    "def imagefn(mols):\n",
    "    out = []\n",
    "    for mol in mols:\n",
    "        if mol is None:\n",
    "            out.append(None)\n",
    "            continue\n",
    "        svg_obj = Draw.MolsToGridImage([mol], molsPerRow=1, subImgSize=(200, 200), useSVG=True)\n",
    "        svg_str = svg_obj.data if hasattr(svg_obj, \"data\") else svg_obj._repr_svg_()\n",
    "        b64 = base64.b64encode(svg_str.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        out.append(b64)\n",
    "    return out\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def featurefn(mol_list, radius=2, n_bits=1024):\n",
    "    \"\"\"\n",
    "    Compute Morgan fingerprints for a list of RDKit molecules, handling partial/incomplete molecules.\n",
    "    \n",
    "    Returns:\n",
    "        fps: np.ndarray of shape (len(mol_list), n_bits)\n",
    "        success_mask: list of bool, True if fingerprint computed successfully, False if fallback used\n",
    "    \"\"\"\n",
    "    fps = np.zeros((len(mol_list), n_bits), dtype=np.uint8)\n",
    "    success_mask = [False] * len(mol_list)\n",
    "\n",
    "    for i, mol in enumerate(mol_list):\n",
    "        if mol is None or mol.GetNumAtoms() == 0:\n",
    "            continue  # leave as zero and False\n",
    "        try:\n",
    "            mol_copy = Chem.Mol(mol)\n",
    "            # Try to sanitize, skip kekulization to avoid RingInfo errors\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol_copy, Chem.SANITIZE_ALL ^ Chem.SANITIZE_KEKULIZE)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Compute Morgan fingerprint\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol_copy, radius=radius, nBits=n_bits)\n",
    "            arr = np.zeros((n_bits,), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "            fps[i] = arr.astype(np.uint8)\n",
    "\n",
    "            success_mask[i] = True\n",
    "        except Exception as e:\n",
    "            # Leave as zero vector, success_mask[i] remains False\n",
    "            #print(f\"{i}: fingerprint failed -> {e}\")\n",
    "            pass\n",
    "\n",
    "    return fps, success_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def textfn(mol_list):\n",
    "    smiles_list = []\n",
    "    for mol in mol_list:\n",
    "        if mol is None:\n",
    "            smiles_list.append(\"[INVALID_NONE]\")\n",
    "            continue\n",
    "        try:\n",
    "            # Try normal smiles\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False)\n",
    "            if smi:\n",
    "                smiles_list.append(smi)\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # Try unsanitized SMILES fallback\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False, isomericSmiles=False)\n",
    "            smiles_list.append(smi if smi else \"[INVALID_EMPTY]\")\n",
    "        except:\n",
    "            smiles_list.append(\"[INVALID_ERROR]\")\n",
    "    return smiles_list\n",
    "        \n",
    "\n",
    "logger = VisLogger(\n",
    "    path=\"./seh_big\",\n",
    "    s0_included = True,\n",
    "    fn_compute_features=featurefn,\n",
    "    fn_state_to_text=textfn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf58ad1-a78e-4e40-a843-ebe38a721214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, n)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs))}, obj_props)\n",
    "        batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "        _, _, losses = algo.compute_batch_losses(model, batch)\n",
    "        #losses.append(loss.item())\n",
    "        avg_rewards.append((log_rewards).exp().mean().item())\n",
    "    batch_idx = []\n",
    "    states = []\n",
    "    logprobs_bw=[]\n",
    "    logprobs_fw=[]\n",
    "    for j, t in enumerate(trajs):\n",
    "        tl = len(t[\"traj\"])\n",
    "        batch_idx += [j]*tl\n",
    "        for s in t[\"traj\"]:\n",
    "            states.append(ctx.graph_to_obj(s[0]))\n",
    "        logprobs_bw.append(t[\"bck_logprobs\"])\n",
    "        # shift to next one\n",
    "        logprobs_fw.append(torch.cat((torch.Tensor([0]), t[\"fwd_logprobs\"][:-1])))\n",
    "        \"\"\"\n",
    "        if j ==0:\n",
    "            print(states)\n",
    "            print(len(states))\n",
    "            print(t[\"fwd_logprobs\"])\n",
    "            print(t[\"bck_logprobs\"])\n",
    "            print(t)\"\"\"\n",
    "    return np.array(batch_idx), states, log_rewards.exp(), losses, torch.cat(logprobs_fw), torch.cat(logprobs_bw)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deddd774150a3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:19:56.858156Z",
     "start_time": "2025-11-25T20:19:56.799160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071f80a577ef49068a7b8de5f4f08ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = 32\n",
    "log_every = 250\n",
    "iterations = 5000\n",
    "samples_per_log = 1000\n",
    "losses = []\n",
    "avg_rewards = []\n",
    "opt = torch.optim.Adam(model.parameters(), 3e-4)\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, 64)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs)) * beta}, obj_props)\n",
    "\n",
    "    batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "    loss, _, _ = algo.compute_batch_losses(model, batch)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    avg_rewards.append((log_rewards / beta).exp().mean().item())\n",
    "\n",
    "    #logging\n",
    "    if (i+1)%log_every==0:\n",
    "        # sample new ones on policy\n",
    "        batch_idx, states, rewards, loss, logprobs_fw, logprobs_bw = sample(samples_per_log)\n",
    "    \n",
    "        logger.log(\n",
    "            batch_idx=batch_idx,\n",
    "            states=states,\n",
    "            total_reward=rewards,\n",
    "            loss = loss,\n",
    "            iteration=i,\n",
    "            logprobs_backward = logprobs_bw,\n",
    "            logprobs_forward = logprobs_fw\n",
    "        )\n",
    "        logger.write_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361df27-2d07-4293-844d-d1ca710bbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f031bc4-ceae-4366-a8ad-3e0db40e47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in range(158):\n",
    "    batch_idx, states, rewards, loss, logprobs_fw, logprobs_bw = sample(64)\n",
    "    final_states = {}\n",
    "    for idx, state in zip(batch_idx, states):\n",
    "        final_states[idx] = state  # overwrites until the last occurrence\n",
    "    final_states_list = [final_states[i] for i in sorted(final_states)]\n",
    "    \n",
    "    features, features_valid = featurefn(final_states_list)\n",
    "    texts = textfn(final_states_list)\n",
    "\n",
    "    logger.create_and_append_testset(\n",
    "        texts = texts,\n",
    "        total_reward=rewards,\n",
    "        features = features.T,\n",
    "        features_valid = features_valid\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86671f03-bc02-41df-aebd-b44edc5e2c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
