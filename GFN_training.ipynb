{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751fb547ec8e93ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T14:52:05.841462Z",
     "start_time": "2025-11-29T14:51:59.110038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import the stuff we need\n",
    "import torch\n",
    "from gflownet.config import init_empty, Config\n",
    "from gflownet.models.graph_transformer import GraphTransformerGFN\n",
    "from gflownet.envs.graph_building_env import GraphBuildingEnv\n",
    "from gflownet.envs.frag_mol_env import FragMolBuildingEnvContext\n",
    "from gflownet.algo.trajectory_balance import TrajectoryBalance\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Get the logger\n",
    "lg = RDLogger.logger()\n",
    "\n",
    "# Disable all RDKit warnings\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "def graph_to_obj(self, g):\n",
    "\n",
    "    def safe_mol(m):\n",
    "        \"\"\"Convert None or invalid input into an empty RDKit molecule.\"\"\"\n",
    "        return m if isinstance(m, Chem.Mol) else Chem.RWMol().GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Base molecule: always start with an empty mol\n",
    "    # ---------------------------------------------------------\n",
    "    mol = Chem.RWMol().GetMol()      # <-- ALWAYS valid, never None\n",
    "    first = True                     # track first fragment\n",
    "\n",
    "    # Atom index offsets\n",
    "    offsets = np.cumsum(\n",
    "        [0] + [self.frags_numatm[g.nodes[i][\"v\"]] for i in g]\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) Add all fragments\n",
    "    # ---------------------------------------------------------\n",
    "    for i in g.nodes:\n",
    "        idx = g.nodes[i][\"v\"]\n",
    "\n",
    "        # force fragment into a valid molecule\n",
    "        frag = safe_mol(self.frags_mol[idx])\n",
    "\n",
    "        if first:\n",
    "            mol = frag\n",
    "            first = False\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol, frag)\n",
    "\n",
    "    # If graph had *no nodes*, mol is still empty â€” that's OK!\n",
    "    rw = Chem.RWMol(mol)  # <-- NOW GUARANTEED SAFE\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) Add bonds\n",
    "    # ---------------------------------------------------------\n",
    "    bond_atoms = []\n",
    "    for a, b in g.edges:\n",
    "        afrag = g.nodes[a][\"v\"]\n",
    "        bfrag = g.nodes[b][\"v\"]\n",
    "\n",
    "        src = g.edges[(a, b)].get(\"src_attach\", 0)\n",
    "        dst = g.edges[(a, b)].get(\"dst_attach\", 0)\n",
    "\n",
    "        try:\n",
    "            u = int(self.frags_stems[afrag][src] + offsets[a])\n",
    "            v = int(self.frags_stems[bfrag][dst] + offsets[b])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rw.AddBond(u, v, Chem.BondType.SINGLE)\n",
    "            bond_atoms.extend([u, v])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    mol = rw.GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4) Remove one H from each attachment atom if possible\n",
    "    # ---------------------------------------------------------\n",
    "    for idx in bond_atoms:\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        h = atom.GetNumExplicitHs()\n",
    "        if h > 0:\n",
    "            atom.SetNumExplicitHs(h - 1)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5) Try sanitizing, but tolerate failure\n",
    "    # ---------------------------------------------------------\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FragMolBuildingEnvContext.graph_to_obj = graph_to_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958c815e8650f898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:44.593469Z",
     "start_time": "2025-11-25T20:17:44.354022Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # For demonstration purposes\n",
    "cfg = Config()\n",
    "env = GraphBuildingEnv()\n",
    "ctx = FragMolBuildingEnvContext()\n",
    "model = GraphTransformerGFN(ctx, cfg)\n",
    "algo = TrajectoryBalance(env, ctx, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce09c59c864edbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:46.688966Z",
     "start_time": "2025-11-25T20:17:46.679011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device('cpu')\n",
    "dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba5674ac77afc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:54.576213Z",
     "start_time": "2025-11-25T20:17:51.353614Z"
    }
   },
   "outputs": [],
   "source": [
    "from gflownet.tasks.seh_frag import SEHTask\n",
    "task = SEHTask(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42fc64c0d8ea240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:18:42.844207Z",
     "start_time": "2025-11-25T20:18:42.840546Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from logger import *\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "import base64\n",
    "from gflownet.envs.graph_building_env import ActionIndex, Graph\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "\n",
    "def imagefn(mols):\n",
    "    out = []\n",
    "    for mol in mols:\n",
    "        if mol is None:\n",
    "            out.append(None)\n",
    "            continue\n",
    "        svg_obj = Draw.MolsToGridImage([mol], molsPerRow=1, subImgSize=(200, 200), useSVG=True)\n",
    "        svg_str = svg_obj.data if hasattr(svg_obj, \"data\") else svg_obj._repr_svg_()\n",
    "        b64 = base64.b64encode(svg_str.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        out.append(b64)\n",
    "    return out\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def featurefn(mol_list, radius=2, n_bits=1024):\n",
    "    \"\"\"\n",
    "    Compute Morgan fingerprints for a list of RDKit molecules, handling partial/incomplete molecules.\n",
    "    \n",
    "    Returns:\n",
    "        fps: np.ndarray of shape (len(mol_list), n_bits)\n",
    "        success_mask: list of bool, True if fingerprint computed successfully, False if fallback used\n",
    "    \"\"\"\n",
    "    fps = np.zeros((len(mol_list), n_bits), dtype=np.uint8)\n",
    "    success_mask = [False] * len(mol_list)\n",
    "\n",
    "    for i, mol in enumerate(mol_list):\n",
    "        if mol is None or mol.GetNumAtoms() == 0:\n",
    "            continue  # leave as zero and False\n",
    "        try:\n",
    "            mol_copy = Chem.Mol(mol)\n",
    "            # Try to sanitize, skip kekulization to avoid RingInfo errors\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol_copy, Chem.SANITIZE_ALL ^ Chem.SANITIZE_KEKULIZE)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Compute Morgan fingerprint\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol_copy, radius=radius, nBits=n_bits)\n",
    "            arr = np.zeros((n_bits,), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "            fps[i] = arr.astype(np.uint8)\n",
    "\n",
    "            success_mask[i] = True\n",
    "        except Exception as e:\n",
    "            # Leave as zero vector, success_mask[i] remains False\n",
    "            #print(f\"{i}: fingerprint failed -> {e}\")\n",
    "            pass\n",
    "\n",
    "    return fps, success_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def textfn(mol_list):\n",
    "    smiles_list = []\n",
    "    for mol in mol_list:\n",
    "        if mol is None:\n",
    "            smiles_list.append(\"[INVALID_NONE]\")\n",
    "            continue\n",
    "        try:\n",
    "            # Try normal smiles\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False)\n",
    "            if smi:\n",
    "                smiles_list.append(smi)\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # Try unsanitized SMILES fallback\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False, isomericSmiles=False)\n",
    "            smiles_list.append(smi if smi else \"[INVALID_EMPTY]\")\n",
    "        except:\n",
    "            smiles_list.append(\"[INVALID_ERROR]\")\n",
    "    return smiles_list\n",
    "        \n",
    "\n",
    "logger = VisLogger(\n",
    "    path=\"./seh_small\",\n",
    "    s0_included = True,\n",
    "    fn_compute_features=featurefn,\n",
    "    fn_state_to_text=textfn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf58ad1-a78e-4e40-a843-ebe38a721214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, n)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs))}, obj_props)\n",
    "        batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "        _, _, losses = algo.compute_batch_losses(model, batch)\n",
    "        #losses.append(loss.item())\n",
    "        avg_rewards.append((log_rewards).exp().mean().item())\n",
    "    batch_idx = []\n",
    "    states = []\n",
    "    logprobs_bw=[]\n",
    "    logprobs_fw=[]\n",
    "    for j, t in enumerate(trajs):\n",
    "        tl = len(t[\"traj\"])\n",
    "        batch_idx += [j]*tl\n",
    "        for s in t[\"traj\"]:\n",
    "            states.append(ctx.graph_to_obj(s[0]))\n",
    "        logprobs_bw.append(t[\"bck_logprobs\"])\n",
    "        # shift to next one\n",
    "        logprobs_fw.append(torch.cat((torch.Tensor([0]), t[\"fwd_logprobs\"][:-1])))\n",
    "        \"\"\"\n",
    "        if j ==0:\n",
    "            print(states)\n",
    "            print(len(states))\n",
    "            print(t[\"fwd_logprobs\"])\n",
    "            print(t[\"bck_logprobs\"])\n",
    "            print(t)\"\"\"\n",
    "    return np.array(batch_idx), states, log_rewards.exp(), losses, torch.cat(logprobs_fw), torch.cat(logprobs_bw)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5deddd774150a3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:19:56.858156Z",
     "start_time": "2025-11-25T20:19:56.799160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1b424d19934345a1e351dfb54c7703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 1632\n",
      "Total edges: 1758\n",
      "Node types:\n",
      "  final: 100\n",
      "  standard: 1531\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 1498 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 106 edges...\n",
      "  Iteration 2: Updating 98 edges...\n",
      "  Iteration 3: Updating 98 edges...\n",
      "  Iteration 4: Updating 98 edges...\n",
      "  Iteration 5: Updating 98 edges...\n",
      "  Iteration 6: Updating 98 edges...\n",
      "  Iteration 7: Updating 98 edges...\n",
      "  Iteration 8: Updating 98 edges...\n",
      "  Iteration 9: Updating 98 edges...\n",
      "  Iteration 10: Updating 98 edges...\n",
      "  Iteration 11: Updating 98 edges...\n",
      "  Iteration 12: Updating 98 edges...\n",
      "  Iteration 13: Updating 96 edges...\n",
      "  Iteration 14: Updating 89 edges...\n",
      "  Iteration 15: Updating 68 edges...\n",
      "  Iteration 16: Updating 40 edges...\n",
      "  Iteration 17: Updating 15 edges...\n",
      "  Iteration 18: Updating 7 edges...\n",
      "  Iteration 19: Updating 3 edges...\n",
      "  Completed in 19 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 1498 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 134\n",
      "  Remaining edges: 256\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 134\n",
      "Total edges: 256\n",
      "Node types:\n",
      "  final: 100\n",
      "  standard: 33\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 3429\n",
      "Total edges: 3978\n",
      "Node types:\n",
      "  final: 200\n",
      "  standard: 3228\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 3166 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 202 edges...\n",
      "  Iteration 2: Updating 198 edges...\n",
      "  Iteration 3: Updating 198 edges...\n",
      "  Iteration 4: Updating 198 edges...\n",
      "  Iteration 5: Updating 197 edges...\n",
      "  Iteration 6: Updating 197 edges...\n",
      "  Iteration 7: Updating 197 edges...\n",
      "  Iteration 8: Updating 197 edges...\n",
      "  Iteration 9: Updating 197 edges...\n",
      "  Iteration 10: Updating 197 edges...\n",
      "  Iteration 11: Updating 197 edges...\n",
      "  Iteration 12: Updating 197 edges...\n",
      "  Iteration 13: Updating 195 edges...\n",
      "  Iteration 14: Updating 184 edges...\n",
      "  Iteration 15: Updating 159 edges...\n",
      "  Iteration 16: Updating 111 edges...\n",
      "  Iteration 17: Updating 74 edges...\n",
      "  Iteration 18: Updating 46 edges...\n",
      "  Iteration 19: Updating 17 edges...\n",
      "  Iteration 20: Updating 7 edges...\n",
      "  Iteration 21: Updating 2 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 3166 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 263\n",
      "  Remaining edges: 811\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 263\n",
      "Total edges: 811\n",
      "Node types:\n",
      "  final: 200\n",
      "  standard: 62\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 4942\n",
      "Total edges: 6254\n",
      "Node types:\n",
      "  final: 300\n",
      "  standard: 4641\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 4554 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 306 edges...\n",
      "  Iteration 2: Updating 298 edges...\n",
      "  Iteration 3: Updating 298 edges...\n",
      "  Iteration 4: Updating 298 edges...\n",
      "  Iteration 5: Updating 297 edges...\n",
      "  Iteration 6: Updating 297 edges...\n",
      "  Iteration 7: Updating 297 edges...\n",
      "  Iteration 8: Updating 297 edges...\n",
      "  Iteration 9: Updating 297 edges...\n",
      "  Iteration 10: Updating 297 edges...\n",
      "  Iteration 11: Updating 297 edges...\n",
      "  Iteration 12: Updating 295 edges...\n",
      "  Iteration 13: Updating 284 edges...\n",
      "  Iteration 14: Updating 242 edges...\n",
      "  Iteration 15: Updating 190 edges...\n",
      "  Iteration 16: Updating 122 edges...\n",
      "  Iteration 17: Updating 77 edges...\n",
      "  Iteration 18: Updating 45 edges...\n",
      "  Iteration 19: Updating 15 edges...\n",
      "  Iteration 20: Updating 6 edges...\n",
      "  Iteration 21: Updating 2 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 4554 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 388\n",
      "  Remaining edges: 1697\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 388\n",
      "Total edges: 1697\n",
      "Node types:\n",
      "  final: 300\n",
      "  standard: 87\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 6506\n",
      "Total edges: 8913\n",
      "Node types:\n",
      "  final: 400\n",
      "  standard: 6105\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 5987 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 405 edges...\n",
      "  Iteration 2: Updating 397 edges...\n",
      "  Iteration 3: Updating 397 edges...\n",
      "  Iteration 4: Updating 397 edges...\n",
      "  Iteration 5: Updating 396 edges...\n",
      "  Iteration 6: Updating 396 edges...\n",
      "  Iteration 7: Updating 396 edges...\n",
      "  Iteration 8: Updating 396 edges...\n",
      "  Iteration 9: Updating 396 edges...\n",
      "  Iteration 10: Updating 396 edges...\n",
      "  Iteration 11: Updating 396 edges...\n",
      "  Iteration 12: Updating 394 edges...\n",
      "  Iteration 13: Updating 377 edges...\n",
      "  Iteration 14: Updating 321 edges...\n",
      "  Iteration 15: Updating 238 edges...\n",
      "  Iteration 16: Updating 147 edges...\n",
      "  Iteration 17: Updating 83 edges...\n",
      "  Iteration 18: Updating 43 edges...\n",
      "  Iteration 19: Updating 14 edges...\n",
      "  Iteration 20: Updating 4 edges...\n",
      "  Iteration 21: Updating 1 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 5987 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 519\n",
      "  Remaining edges: 2923\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 519\n",
      "Total edges: 2923\n",
      "Node types:\n",
      "  final: 400\n",
      "  standard: 118\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 8152\n",
      "Total edges: 11970\n",
      "Node types:\n",
      "  final: 500\n",
      "  standard: 7651\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 7509 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 505 edges...\n",
      "  Iteration 2: Updating 497 edges...\n",
      "  Iteration 3: Updating 497 edges...\n",
      "  Iteration 4: Updating 497 edges...\n",
      "  Iteration 5: Updating 496 edges...\n",
      "  Iteration 6: Updating 496 edges...\n",
      "  Iteration 7: Updating 496 edges...\n",
      "  Iteration 8: Updating 496 edges...\n",
      "  Iteration 9: Updating 496 edges...\n",
      "  Iteration 10: Updating 496 edges...\n",
      "  Iteration 11: Updating 496 edges...\n",
      "  Iteration 12: Updating 494 edges...\n",
      "  Iteration 13: Updating 475 edges...\n",
      "  Iteration 14: Updating 410 edges...\n",
      "  Iteration 15: Updating 309 edges...\n",
      "  Iteration 16: Updating 192 edges...\n",
      "  Iteration 17: Updating 100 edges...\n",
      "  Iteration 18: Updating 43 edges...\n",
      "  Iteration 19: Updating 16 edges...\n",
      "  Iteration 20: Updating 4 edges...\n",
      "  Iteration 21: Updating 1 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 7509 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 643\n",
      "  Remaining edges: 4458\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 643\n",
      "Total edges: 4458\n",
      "Node types:\n",
      "  final: 500\n",
      "  standard: 142\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 9794\n",
      "Total edges: 15337\n",
      "Node types:\n",
      "  final: 600\n",
      "  standard: 9193\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 9026 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 605 edges...\n",
      "  Iteration 2: Updating 597 edges...\n",
      "  Iteration 3: Updating 597 edges...\n",
      "  Iteration 4: Updating 597 edges...\n",
      "  Iteration 5: Updating 596 edges...\n",
      "  Iteration 6: Updating 596 edges...\n",
      "  Iteration 7: Updating 596 edges...\n",
      "  Iteration 8: Updating 596 edges...\n",
      "  Iteration 9: Updating 596 edges...\n",
      "  Iteration 10: Updating 596 edges...\n",
      "  Iteration 11: Updating 596 edges...\n",
      "  Iteration 12: Updating 594 edges...\n",
      "  Iteration 13: Updating 571 edges...\n",
      "  Iteration 14: Updating 499 edges...\n",
      "  Iteration 15: Updating 372 edges...\n",
      "  Iteration 16: Updating 234 edges...\n",
      "  Iteration 17: Updating 118 edges...\n",
      "  Iteration 18: Updating 49 edges...\n",
      "  Iteration 19: Updating 19 edges...\n",
      "  Iteration 20: Updating 4 edges...\n",
      "  Iteration 21: Updating 1 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 9026 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 768\n",
      "  Remaining edges: 6308\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 768\n",
      "Total edges: 6308\n",
      "Node types:\n",
      "  final: 600\n",
      "  standard: 167\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 11398\n",
      "Total edges: 18976\n",
      "Node types:\n",
      "  final: 700\n",
      "  standard: 10697\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 10497 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 703 edges...\n",
      "  Iteration 2: Updating 697 edges...\n",
      "  Iteration 3: Updating 697 edges...\n",
      "  Iteration 4: Updating 697 edges...\n",
      "  Iteration 5: Updating 696 edges...\n",
      "  Iteration 6: Updating 696 edges...\n",
      "  Iteration 7: Updating 696 edges...\n",
      "  Iteration 8: Updating 696 edges...\n",
      "  Iteration 9: Updating 696 edges...\n",
      "  Iteration 10: Updating 696 edges...\n",
      "  Iteration 11: Updating 696 edges...\n",
      "  Iteration 12: Updating 694 edges...\n",
      "  Iteration 13: Updating 668 edges...\n",
      "  Iteration 14: Updating 578 edges...\n",
      "  Iteration 15: Updating 432 edges...\n",
      "  Iteration 16: Updating 256 edges...\n",
      "  Iteration 17: Updating 130 edges...\n",
      "  Iteration 18: Updating 52 edges...\n",
      "  Iteration 19: Updating 18 edges...\n",
      "  Iteration 20: Updating 4 edges...\n",
      "  Iteration 21: Updating 1 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 10497 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 901\n",
      "  Remaining edges: 8477\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 901\n",
      "Total edges: 8477\n",
      "Node types:\n",
      "  final: 700\n",
      "  standard: 200\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 13158\n",
      "Total edges: 23118\n",
      "Node types:\n",
      "  final: 800\n",
      "  standard: 12357\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 12123 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 811 edges...\n",
      "  Iteration 2: Updating 797 edges...\n",
      "  Iteration 3: Updating 797 edges...\n",
      "  Iteration 4: Updating 797 edges...\n",
      "  Iteration 5: Updating 796 edges...\n",
      "  Iteration 6: Updating 796 edges...\n",
      "  Iteration 7: Updating 796 edges...\n",
      "  Iteration 8: Updating 796 edges...\n",
      "  Iteration 9: Updating 796 edges...\n",
      "  Iteration 10: Updating 796 edges...\n",
      "  Iteration 11: Updating 796 edges...\n",
      "  Iteration 12: Updating 794 edges...\n",
      "  Iteration 13: Updating 764 edges...\n",
      "  Iteration 14: Updating 672 edges...\n",
      "  Iteration 15: Updating 519 edges...\n",
      "  Iteration 16: Updating 317 edges...\n",
      "  Iteration 17: Updating 178 edges...\n",
      "  Iteration 18: Updating 72 edges...\n",
      "  Iteration 19: Updating 27 edges...\n",
      "  Iteration 20: Updating 9 edges...\n",
      "  Iteration 21: Updating 2 edges...\n",
      "  Iteration 22: Updating 1 edges...\n",
      "  Completed in 22 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 12123 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 1035\n",
      "  Remaining edges: 10989\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 1035\n",
      "Total edges: 10989\n",
      "Node types:\n",
      "  final: 800\n",
      "  standard: 234\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 14885\n",
      "Total edges: 27525\n",
      "Node types:\n",
      "  final: 900\n",
      "  standard: 13984\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 13730 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 911 edges...\n",
      "  Iteration 2: Updating 897 edges...\n",
      "  Iteration 3: Updating 897 edges...\n",
      "  Iteration 4: Updating 897 edges...\n",
      "  Iteration 5: Updating 896 edges...\n",
      "  Iteration 6: Updating 896 edges...\n",
      "  Iteration 7: Updating 896 edges...\n",
      "  Iteration 8: Updating 896 edges...\n",
      "  Iteration 9: Updating 896 edges...\n",
      "  Iteration 10: Updating 896 edges...\n",
      "  Iteration 11: Updating 896 edges...\n",
      "  Iteration 12: Updating 894 edges...\n",
      "  Iteration 13: Updating 863 edges...\n",
      "  Iteration 14: Updating 770 edges...\n",
      "  Iteration 15: Updating 598 edges...\n",
      "  Iteration 16: Updating 382 edges...\n",
      "  Iteration 17: Updating 216 edges...\n",
      "  Iteration 18: Updating 91 edges...\n",
      "  Iteration 19: Updating 34 edges...\n",
      "  Iteration 20: Updating 11 edges...\n",
      "  Iteration 21: Updating 3 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 13730 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 1155\n",
      "  Remaining edges: 13789\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 1155\n",
      "Total edges: 13789\n",
      "Node types:\n",
      "  final: 900\n",
      "  standard: 254\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 16593\n",
      "Total edges: 32212\n",
      "Node types:\n",
      "  final: 1000\n",
      "  standard: 15592\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 15312 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 1013 edges...\n",
      "  Iteration 2: Updating 997 edges...\n",
      "  Iteration 3: Updating 997 edges...\n",
      "  Iteration 4: Updating 997 edges...\n",
      "  Iteration 5: Updating 996 edges...\n",
      "  Iteration 6: Updating 996 edges...\n",
      "  Iteration 7: Updating 996 edges...\n",
      "  Iteration 8: Updating 996 edges...\n",
      "  Iteration 9: Updating 996 edges...\n",
      "  Iteration 10: Updating 996 edges...\n",
      "  Iteration 11: Updating 996 edges...\n",
      "  Iteration 12: Updating 994 edges...\n",
      "  Iteration 13: Updating 962 edges...\n",
      "  Iteration 14: Updating 865 edges...\n",
      "  Iteration 15: Updating 682 edges...\n",
      "  Iteration 16: Updating 442 edges...\n",
      "  Iteration 17: Updating 239 edges...\n",
      "  Iteration 18: Updating 106 edges...\n",
      "  Iteration 19: Updating 39 edges...\n",
      "  Iteration 20: Updating 11 edges...\n",
      "  Iteration 21: Updating 3 edges...\n",
      "  Completed in 21 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 15312 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 1281\n",
      "  Remaining edges: 16893\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 1281\n",
      "Total edges: 16893\n",
      "Node types:\n",
      "  final: 1000\n",
      "  standard: 280\n",
      "  start: 1\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "beta = 32\n",
    "log_every = 20\n",
    "iterations = 200\n",
    "samples_per_log = 100\n",
    "losses = []\n",
    "avg_rewards = []\n",
    "opt = torch.optim.Adam(model.parameters(), 3e-4)\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, 64)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs)) * beta}, obj_props)\n",
    "\n",
    "    batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "    loss, _, _ = algo.compute_batch_losses(model, batch)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    avg_rewards.append((log_rewards / beta).exp().mean().item())\n",
    "\n",
    "    #logging\n",
    "    if (i+1)%log_every==0:\n",
    "        # sample new ones on policy\n",
    "        batch_idx, states, rewards, loss, logprobs_fw, logprobs_bw = sample(samples_per_log)\n",
    "    \n",
    "        logger.log(\n",
    "            batch_idx=batch_idx,\n",
    "            states=states,\n",
    "            total_reward=rewards,\n",
    "            loss = loss,\n",
    "            iteration=i,\n",
    "            logprobs_backward = logprobs_bw,\n",
    "            logprobs_forward = logprobs_fw\n",
    "        )\n",
    "        logger.write_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2361df27-2d07-4293-844d-d1ca710bbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f031bc4-ceae-4366-a8ad-3e0db40e47e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64 64 64\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "index idx_points_text already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m texts \u001b[38;5;241m=\u001b[39m textfn(final_states_list)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texts), \u001b[38;5;28mlen\u001b[39m(features_valid), \u001b[38;5;28mlen\u001b[39m(rewards), features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_append_testset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_reward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures_valid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeatures_valid\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/Master/pilot/logger.py:435\u001b[0m, in \u001b[0;36mVisLogger.create_and_append_testset\u001b[0;34m(self, texts, total_reward, metrics, features, features_valid)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# create indices the first time\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_exists:\n\u001b[0;32m--> 435\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE INDEX idx_points_text ON testset(text)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE INDEX idx_points_reward ON testset(total_reward)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mOperationalError\u001b[0m: index idx_points_text already exists"
     ]
    }
   ],
   "source": [
    "for batch in range(16):\n",
    "    batch_idx, states, rewards, loss, logprobs_fw, logprobs_bw = sample(64)\n",
    "    final_states = {}\n",
    "    for idx, state in zip(batch_idx, states):\n",
    "        final_states[idx] = state  # overwrites until the last occurrence\n",
    "    final_states_list = [final_states[i] for i in sorted(final_states)]\n",
    "    \n",
    "    features, features_valid = featurefn(final_states_list)\n",
    "    texts = textfn(final_states_list)\n",
    "    print(len(texts), len(features_valid), len(rewards), features.shape[0])\n",
    "\n",
    "    logger.create_and_append_testset(\n",
    "        texts = texts,\n",
    "        total_reward=rewards,\n",
    "        features = features.T,\n",
    "        features_valid = features_valid\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86671f03-bc02-41df-aebd-b44edc5e2c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
