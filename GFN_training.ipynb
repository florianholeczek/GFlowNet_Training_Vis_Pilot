{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751fb547ec8e93ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T14:52:05.841462Z",
     "start_time": "2025-11-29T14:51:59.110038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import the stuff we need\n",
    "import torch\n",
    "from gflownet.config import init_empty, Config\n",
    "from gflownet.models.graph_transformer import GraphTransformerGFN\n",
    "from gflownet.envs.graph_building_env import GraphBuildingEnv\n",
    "from gflownet.envs.frag_mol_env import FragMolBuildingEnvContext\n",
    "from gflownet.algo.trajectory_balance import TrajectoryBalance\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Get the logger\n",
    "lg = RDLogger.logger()\n",
    "\n",
    "# Disable all RDKit warnings\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "def graph_to_obj(self, g):\n",
    "\n",
    "    def safe_mol(m):\n",
    "        \"\"\"Convert None or invalid input into an empty RDKit molecule.\"\"\"\n",
    "        return m if isinstance(m, Chem.Mol) else Chem.RWMol().GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Base molecule: always start with an empty mol\n",
    "    # ---------------------------------------------------------\n",
    "    mol = Chem.RWMol().GetMol()      # <-- ALWAYS valid, never None\n",
    "    first = True                     # track first fragment\n",
    "\n",
    "    # Atom index offsets\n",
    "    offsets = np.cumsum(\n",
    "        [0] + [self.frags_numatm[g.nodes[i][\"v\"]] for i in g]\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) Add all fragments\n",
    "    # ---------------------------------------------------------\n",
    "    for i in g.nodes:\n",
    "        idx = g.nodes[i][\"v\"]\n",
    "\n",
    "        # force fragment into a valid molecule\n",
    "        frag = safe_mol(self.frags_mol[idx])\n",
    "\n",
    "        if first:\n",
    "            mol = frag\n",
    "            first = False\n",
    "        else:\n",
    "            mol = Chem.CombineMols(mol, frag)\n",
    "\n",
    "    # If graph had *no nodes*, mol is still empty â€” that's OK!\n",
    "    rw = Chem.RWMol(mol)  # <-- NOW GUARANTEED SAFE\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) Add bonds\n",
    "    # ---------------------------------------------------------\n",
    "    bond_atoms = []\n",
    "    for a, b in g.edges:\n",
    "        afrag = g.nodes[a][\"v\"]\n",
    "        bfrag = g.nodes[b][\"v\"]\n",
    "\n",
    "        src = g.edges[(a, b)].get(\"src_attach\", 0)\n",
    "        dst = g.edges[(a, b)].get(\"dst_attach\", 0)\n",
    "\n",
    "        try:\n",
    "            u = int(self.frags_stems[afrag][src] + offsets[a])\n",
    "            v = int(self.frags_stems[bfrag][dst] + offsets[b])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rw.AddBond(u, v, Chem.BondType.SINGLE)\n",
    "            bond_atoms.extend([u, v])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    mol = rw.GetMol()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4) Remove one H from each attachment atom if possible\n",
    "    # ---------------------------------------------------------\n",
    "    for idx in bond_atoms:\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        h = atom.GetNumExplicitHs()\n",
    "        if h > 0:\n",
    "            atom.SetNumExplicitHs(h - 1)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5) Try sanitizing, but tolerate failure\n",
    "    # ---------------------------------------------------------\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FragMolBuildingEnvContext.graph_to_obj = graph_to_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958c815e8650f898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:44.593469Z",
     "start_time": "2025-11-25T20:17:44.354022Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # For demonstration purposes\n",
    "cfg = Config()\n",
    "env = GraphBuildingEnv()\n",
    "ctx = FragMolBuildingEnvContext()\n",
    "model = GraphTransformerGFN(ctx, cfg)\n",
    "algo = TrajectoryBalance(env, ctx, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce09c59c864edbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:46.688966Z",
     "start_time": "2025-11-25T20:17:46.679011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device('cpu')\n",
    "dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba5674ac77afc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:17:54.576213Z",
     "start_time": "2025-11-25T20:17:51.353614Z"
    }
   },
   "outputs": [],
   "source": [
    "from gflownet.tasks.seh_frag import SEHTask\n",
    "task = SEHTask(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42fc64c0d8ea240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:18:42.844207Z",
     "start_time": "2025-11-25T20:18:42.840546Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from logger import *\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "import base64\n",
    "from gflownet.envs.graph_building_env import ActionIndex, Graph\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "\n",
    "def imagefn(mols):\n",
    "    out = []\n",
    "    for mol in mols:\n",
    "        if mol is None:\n",
    "            out.append(None)\n",
    "            continue\n",
    "        svg_obj = Draw.MolsToGridImage([mol], molsPerRow=1, subImgSize=(200, 200), useSVG=True)\n",
    "        svg_str = svg_obj.data if hasattr(svg_obj, \"data\") else svg_obj._repr_svg_()\n",
    "        b64 = base64.b64encode(svg_str.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        out.append(b64)\n",
    "    return out\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import numpy as np\n",
    "\n",
    "def featurefn(mol_list, radius=2, n_bits=1024):\n",
    "    \"\"\"\n",
    "    Compute Morgan fingerprints for a list of RDKit molecules, handling partial/incomplete molecules.\n",
    "    \n",
    "    Returns:\n",
    "        fps: np.ndarray of shape (len(mol_list), n_bits)\n",
    "        success_mask: list of bool, True if fingerprint computed successfully, False if fallback used\n",
    "    \"\"\"\n",
    "    fps = np.zeros((len(mol_list), n_bits), dtype=np.uint8)\n",
    "    success_mask = [False] * len(mol_list)\n",
    "\n",
    "    for i, mol in enumerate(mol_list):\n",
    "        if mol is None or mol.GetNumAtoms() == 0:\n",
    "            continue  # leave as zero and False\n",
    "        try:\n",
    "            mol_copy = Chem.Mol(mol)\n",
    "            # Try to sanitize, skip kekulization to avoid RingInfo errors\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol_copy, Chem.SANITIZE_ALL ^ Chem.SANITIZE_KEKULIZE)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Compute Morgan fingerprint\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol_copy, radius=radius, nBits=n_bits)\n",
    "            arr = np.zeros((n_bits,), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "            fps[i] = arr.astype(np.uint8)\n",
    "\n",
    "            success_mask[i] = True\n",
    "        except Exception as e:\n",
    "            # Leave as zero vector, success_mask[i] remains False\n",
    "            #print(f\"{i}: fingerprint failed -> {e}\")\n",
    "            pass\n",
    "\n",
    "    return fps, success_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def textfn(mol_list):\n",
    "    smiles_list = []\n",
    "    for mol in mol_list:\n",
    "        if mol is None:\n",
    "            smiles_list.append(\"[INVALID_NONE]\")\n",
    "            continue\n",
    "        try:\n",
    "            # Try normal smiles\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False)\n",
    "            if smi:\n",
    "                smiles_list.append(smi)\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # Try unsanitized SMILES fallback\n",
    "            smi = Chem.MolToSmiles(mol, canonical=False, isomericSmiles=False)\n",
    "            smiles_list.append(smi if smi else \"[INVALID_EMPTY]\")\n",
    "        except:\n",
    "            smiles_list.append(\"[INVALID_ERROR]\")\n",
    "    return smiles_list\n",
    "        \n",
    "\n",
    "logger = VisLogger(\n",
    "    #path=\"./seh_small\",\n",
    "    s0_included = True,\n",
    "    fn_compute_features=featurefn,\n",
    "    fn_state_to_text=textfn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf58ad1-a78e-4e40-a843-ebe38a721214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, n)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs))}, obj_props)\n",
    "        batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "        _, _, losses = algo.compute_batch_losses(model, batch)\n",
    "        #losses.append(loss.item())\n",
    "        avg_rewards.append((log_rewards).exp().mean().item())\n",
    "    batch_idx = []\n",
    "    states = []\n",
    "    logprobs_bw=[]\n",
    "    logprobs_fw=[]\n",
    "    for j, t in enumerate(trajs):\n",
    "        tl = len(t[\"traj\"])\n",
    "        batch_idx += [j]*tl\n",
    "        for s in t[\"traj\"]:\n",
    "            states.append(ctx.graph_to_obj(s[0]))\n",
    "        logprobs_bw.append(t[\"bck_logprobs\"])\n",
    "        # shift to next one\n",
    "        logprobs_fw.append(torch.cat((torch.Tensor([0]), t[\"fwd_logprobs\"][:-1])))\n",
    "    return np.array(batch_idx), states, log_rewards.exp(), losses, torch.cat(logprobs_fw), torch.cat(logprobs_bw)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5deddd774150a3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T20:19:56.858156Z",
     "start_time": "2025-11-25T20:19:56.799160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38af2e5f27084594be8cdc5fb8efbe23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505,)\n",
      "1505\n",
      "torch.Size([100])\n",
      "100\n",
      "torch.Size([1505])\n",
      "torch.Size([1505])\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 866\n",
      "Total edges: 915\n",
      "Node types:\n",
      "  final: 99\n",
      "  standard: 766\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 738 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 84 edges...\n",
      "  Iteration 2: Updating 77 edges...\n",
      "  Iteration 3: Updating 64 edges...\n",
      "  Iteration 4: Updating 60 edges...\n",
      "  Iteration 5: Updating 51 edges...\n",
      "  Iteration 6: Updating 49 edges...\n",
      "  Iteration 7: Updating 46 edges...\n",
      "  Iteration 8: Updating 44 edges...\n",
      "  Iteration 9: Updating 40 edges...\n",
      "  Iteration 10: Updating 40 edges...\n",
      "  Iteration 11: Updating 38 edges...\n",
      "  Iteration 12: Updating 37 edges...\n",
      "  Iteration 13: Updating 36 edges...\n",
      "  Iteration 14: Updating 36 edges...\n",
      "  Iteration 15: Updating 28 edges...\n",
      "  Iteration 16: Updating 16 edges...\n",
      "  Iteration 17: Updating 6 edges...\n",
      "  Iteration 18: Updating 2 edges...\n",
      "  Iteration 19: Updating 1 edges...\n",
      "  Completed in 19 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 738 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 128\n",
      "  Remaining edges: 176\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 128\n",
      "Total edges: 176\n",
      "Node types:\n",
      "  final: 98\n",
      "  standard: 29\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "(1784,)\n",
      "1784\n",
      "torch.Size([100])\n",
      "100\n",
      "torch.Size([1784])\n",
      "torch.Size([1784])\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 1892\n",
      "Total edges: 2213\n",
      "Node types:\n",
      "  final: 199\n",
      "  standard: 1692\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 1641 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 163 edges...\n",
      "  Iteration 2: Updating 156 edges...\n",
      "  Iteration 3: Updating 128 edges...\n",
      "  Iteration 4: Updating 125 edges...\n",
      "  Iteration 5: Updating 109 edges...\n",
      "  Iteration 6: Updating 108 edges...\n",
      "  Iteration 7: Updating 101 edges...\n",
      "  Iteration 8: Updating 100 edges...\n",
      "  Iteration 9: Updating 95 edges...\n",
      "  Iteration 10: Updating 94 edges...\n",
      "  Iteration 11: Updating 89 edges...\n",
      "  Iteration 12: Updating 89 edges...\n",
      "  Iteration 13: Updating 87 edges...\n",
      "  Iteration 14: Updating 86 edges...\n",
      "  Iteration 15: Updating 65 edges...\n",
      "  Iteration 16: Updating 32 edges...\n",
      "  Iteration 17: Updating 11 edges...\n",
      "  Iteration 18: Updating 2 edges...\n",
      "  Iteration 19: Updating 1 edges...\n",
      "  Completed in 19 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 1641 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 251\n",
      "  Remaining edges: 572\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 251\n",
      "Total edges: 572\n",
      "Node types:\n",
      "  final: 199\n",
      "  standard: 51\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "(2204,)\n",
      "2204\n",
      "torch.Size([100])\n",
      "100\n",
      "torch.Size([2204])\n",
      "torch.Size([2204])\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 3213\n",
      "Total edges: 4046\n",
      "Node types:\n",
      "  final: 299\n",
      "  standard: 2913\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 2843 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 259 edges...\n",
      "  Iteration 2: Updating 249 edges...\n",
      "  Iteration 3: Updating 216 edges...\n",
      "  Iteration 4: Updating 210 edges...\n",
      "  Iteration 5: Updating 191 edges...\n",
      "  Iteration 6: Updating 190 edges...\n",
      "  Iteration 7: Updating 179 edges...\n",
      "  Iteration 8: Updating 178 edges...\n",
      "  Iteration 9: Updating 172 edges...\n",
      "  Iteration 10: Updating 171 edges...\n",
      "  Iteration 11: Updating 164 edges...\n",
      "  Iteration 12: Updating 163 edges...\n",
      "  Iteration 13: Updating 160 edges...\n",
      "  Iteration 14: Updating 156 edges...\n",
      "  Iteration 15: Updating 113 edges...\n",
      "  Iteration 16: Updating 47 edges...\n",
      "  Iteration 17: Updating 22 edges...\n",
      "  Iteration 18: Updating 3 edges...\n",
      "  Iteration 19: Updating 1 edges...\n",
      "  Completed in 19 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 2843 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 370\n",
      "  Remaining edges: 1202\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 370\n",
      "Total edges: 1202\n",
      "Node types:\n",
      "  final: 299\n",
      "  standard: 70\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "(2294,)\n",
      "2294\n",
      "torch.Size([100])\n",
      "100\n",
      "torch.Size([2294])\n",
      "torch.Size([2294])\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 4657\n",
      "Total edges: 6246\n",
      "Node types:\n",
      "  final: 399\n",
      "  standard: 4257\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 4170 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 352 edges...\n",
      "  Iteration 2: Updating 339 edges...\n",
      "  Iteration 3: Updating 303 edges...\n",
      "  Iteration 4: Updating 299 edges...\n",
      "  Iteration 5: Updating 277 edges...\n",
      "  Iteration 6: Updating 276 edges...\n",
      "  Iteration 7: Updating 263 edges...\n",
      "  Iteration 8: Updating 262 edges...\n",
      "  Iteration 9: Updating 255 edges...\n",
      "  Iteration 10: Updating 254 edges...\n",
      "  Iteration 11: Updating 247 edges...\n",
      "  Iteration 12: Updating 246 edges...\n",
      "  Iteration 13: Updating 243 edges...\n",
      "  Iteration 14: Updating 235 edges...\n",
      "  Iteration 15: Updating 178 edges...\n",
      "  Iteration 16: Updating 92 edges...\n",
      "  Iteration 17: Updating 40 edges...\n",
      "  Iteration 18: Updating 10 edges...\n",
      "  Iteration 19: Updating 1 edges...\n",
      "  Completed in 19 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 4170 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 487\n",
      "  Remaining edges: 2074\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 487\n",
      "Total edges: 2074\n",
      "Node types:\n",
      "  final: 399\n",
      "  standard: 87\n",
      "  start: 1\n",
      "\n",
      "Done!\n",
      "(2534,)\n",
      "2534\n",
      "torch.Size([100])\n",
      "100\n",
      "torch.Size([2534])\n",
      "torch.Size([2534])\n",
      "Building initial graph...\n",
      "Initial graph built successfully\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 6278\n",
      "Total edges: 8927\n",
      "Node types:\n",
      "  final: 499\n",
      "  standard: 5778\n",
      "  start: 1\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Starting truncation...\n",
      "Step 1: Identifying removable nodes...\n",
      "  Found 5665 removable nodes\n",
      "Step 2: Creating successor lookup table...\n",
      "Step 3: Bypassing chains...\n",
      "  Iteration 1: Updating 448 edges...\n",
      "  Iteration 2: Updating 436 edges...\n",
      "  Iteration 3: Updating 400 edges...\n",
      "  Iteration 4: Updating 395 edges...\n",
      "  Iteration 5: Updating 374 edges...\n",
      "  Iteration 6: Updating 373 edges...\n",
      "  Iteration 7: Updating 360 edges...\n",
      "  Iteration 8: Updating 359 edges...\n",
      "  Iteration 9: Updating 352 edges...\n",
      "  Iteration 10: Updating 351 edges...\n",
      "  Iteration 11: Updating 344 edges...\n",
      "  Iteration 12: Updating 343 edges...\n",
      "  Iteration 13: Updating 338 edges...\n",
      "  Iteration 14: Updating 326 edges...\n",
      "  Iteration 15: Updating 253 edges...\n",
      "  Iteration 16: Updating 132 edges...\n",
      "  Iteration 17: Updating 58 edges...\n",
      "  Iteration 18: Updating 19 edges...\n",
      "  Iteration 19: Updating 6 edges...\n",
      "  Completed in 19 iterations\n",
      "Step 4: Cleaning up internal chain edges...\n",
      "Step 5: Removing nodes...\n",
      "  Deleted 5665 nodes\n",
      "Step 6: Cleaning up temporary tables...\n",
      "Compression complete!\n",
      "\n",
      "Summary:\n",
      "  Remaining nodes: 613\n",
      "  Remaining edges: 3260\n",
      "\n",
      "=== Graph Statistics ===\n",
      "Total nodes: 613\n",
      "Total edges: 3260\n",
      "Node types:\n",
      "  final: 499\n",
      "  standard: 113\n",
      "  start: 1\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "beta = 32\n",
    "log_every = 2\n",
    "iterations = 10\n",
    "samples_per_log = 100\n",
    "losses = []\n",
    "avg_rewards = []\n",
    "opt = torch.optim.Adam(model.parameters(), 3e-4)\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    with torch.no_grad():  # We don't need to compute gradients here, they will be later\n",
    "        trajs = algo.create_training_data_from_own_samples(model, 64)\n",
    "\n",
    "        objs = [ctx.graph_to_obj(i['result']) for i in trajs]\n",
    "        obj_props, _ = task.compute_obj_properties(objs)\n",
    "        log_rewards = task.cond_info_to_logreward({'beta': torch.ones(len(trajs)) * beta}, obj_props)\n",
    "\n",
    "    batch = algo.construct_batch(trajs, None, log_rewards).to(dev)\n",
    "    loss, _, _ = algo.compute_batch_losses(model, batch)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    avg_rewards.append((log_rewards / beta).exp().mean().item())\n",
    "\n",
    "    #logging\n",
    "    if (i+1)%log_every==0:\n",
    "        # sample new ones on policy\n",
    "        batch_idx, states, rewards, loss, logprobs_fw, logprobs_bw = sample(samples_per_log)\n",
    "        print(batch_idx.shape)\n",
    "        print(len(states))\n",
    "        print(rewards.shape)\n",
    "        print(len(loss))\n",
    "        print(logprobs_fw.shape)\n",
    "        print(logprobs_bw.shape)\n",
    "    \n",
    "        logger.log(\n",
    "            batch_idx=batch_idx,\n",
    "            states=states,\n",
    "            total_reward=rewards,\n",
    "            loss = loss,\n",
    "            iteration=i,\n",
    "            logprobs_backward = logprobs_bw,\n",
    "            logprobs_forward = logprobs_fw\n",
    "        )\n",
    "        logger.write_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361df27-2d07-4293-844d-d1ca710bbb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
